import os
import csv
import joblib
import numpy as np
# import pandas as pd  <-- ç§»é™¤ pandas ä¾èµ–
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, accuracy_score, f1_score
import tkinter as tk
from tkinter import filedialog
from tqdm import tqdm
import cv2  # ç¡®ä¿å¯¼å…¥ cv2
import matplotlib.pyplot as plt
from scipy import stats

# å¼•å…¥æ ¸å¿ƒ
from detect_birds_multi_maskenabled import BirdDetector, load_best_available_image
from sharpness_evaluator_by_frequence import calculate_sharpness_fft

ROI_STANDARD_SIZE = 1600

# å®šä¹‰ç±»åˆ«åç§°æ˜ å°„ (ç”¨äºæ˜¾ç¤º)
CLASS_NAMES = ['Trash', 'Soft', 'Perfect'] # å¯¹åº” 0, 1, 2

def select_folder():
    root = tk.Tk(); root.withdraw()
    path = filedialog.askdirectory(title="é€‰æ‹©åŒ…å« labels.csv çš„æ–‡ä»¶å¤¹")
    root.destroy()
    return path

# === å‡çº§ç‰ˆç‰¹å¾æå–å™¨ (Mask-Aware V2) ===
def extract_enhanced_features(roi_img):
    """
    é’ˆå¯¹ã€çº¯é»‘èƒŒæ™¯ ROIã€‘ä¼˜åŒ–çš„ç‰¹å¾æå–å™¨
    æ ¸å¿ƒé€»è¾‘ï¼šæ’é™¤é®ç½©è¾¹ç¼˜å¹²æ‰°ï¼Œåªè®¡ç®—èº«ä½“å†…éƒ¨çš„é”åº¦
    """
    if roi_img is None: return None
    
    # 1. é¢„å¤„ç†
    if len(roi_img.shape) == 3:
        gray = cv2.cvtColor(roi_img, cv2.COLOR_BGR2GRAY)
    else:
        gray = roi_img

    # 2. ç”Ÿæˆ"å†…éƒ¨æ©è†œ" (Inner Mask)
    # é€»è¾‘ï¼šæ‰¾å‡ºéé»‘åŒºåŸŸ -> å‘å†…è…èš€ -> åªè®¡ç®—è¿™ä¸ªèŒƒå›´å†…çš„æ¢¯åº¦
    # è¿™æ ·èƒ½å½»åº•é¿å¼€æŠ å›¾äº§ç”Ÿçš„é”åˆ©è¾¹ç¼˜
    
    # äºŒå€¼åŒ–æ‰¾å‡ºé¸Ÿçš„åŒºåŸŸ (é0å³ä¸ºé¸Ÿ)
    _, binary_mask = cv2.threshold(gray, 1, 255, cv2.THRESH_BINARY)
    
    # åŠ¨æ€è®¡ç®—è…èš€é‡ (çº¦å çŸ­è¾¹çš„ 1%)
    h, w = gray.shape
    erode_size = max(3, int(min(h, w) * 0.01))
    kernel = np.ones((erode_size, erode_size), np.uint8)
    
    # å‘å†…è…èš€ï¼Œå¾—åˆ°"ç»å¯¹å®‰å…¨çš„å†…éƒ¨åŒºåŸŸ"
    inner_mask = cv2.erode(binary_mask, kernel, iterations=2)
    
    # è®¡ç®—æœ‰æ•ˆåƒç´ æ•°
    valid_pixels = cv2.countNonZero(inner_mask)
    if valid_pixels == 0:
        # é¸Ÿå¤ªå°ï¼Œè…èš€æ²¡äº†ï¼Œå›é€€åˆ°åŸå§‹ mask
        inner_mask = binary_mask
        valid_pixels = cv2.countNonZero(inner_mask)
        if valid_pixels == 0: return [0]*6 # çº¯é»‘å›¾

    # 3. è®¡ç®—æ¢¯åº¦ (Sobel)
    gx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
    gy = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
    magnitude = cv2.magnitude(gx, gy)
    
    # === å…³é”®æ­¥éª¤ï¼šåªæå– inner_mask åŒºåŸŸå†…çš„æ¢¯åº¦å€¼ ===
    valid_gradients = magnitude[inner_mask > 0]
    
    if len(valid_gradients) == 0: return [0]*6

    # ç‰¹å¾ A: å†…éƒ¨å³°å€¼æ¢¯åº¦ (95% åˆ†ä½) - åŒºåˆ† Soft/Perfect çš„æ ¸å¿ƒ
    feat_peak_grad = np.percentile(valid_gradients, 95)
    
    # ç‰¹å¾ B: å†…éƒ¨å¹³å‡æ¢¯åº¦ - åæ˜ æ•´ä½“çº¹ç†
    feat_mean_grad = np.mean(valid_gradients)
    
    # ç‰¹å¾ C: æ¢¯åº¦æ ‡å‡†å·® - åæ˜ çº¹ç†å¤æ‚åº¦
    feat_std_grad = np.std(valid_gradients)

    # 4. FFT é¢‘åŸŸåˆ†æ (è¾…åŠ©åˆ¤æ–­å™ªç‚¹)
    # FFT éš¾ä»¥å®Œå…¨æ’é™¤è¾¹ç¼˜æ•ˆåº”ï¼Œä½†ä½œä¸ºè¾…åŠ©ç‰¹å¾ä¾ç„¶æœ‰æ•ˆ
    feat_fft_mid = calculate_sharpness_fft(roi_img, low_cut=0.10, high_cut=0.30)
    feat_fft_high = calculate_sharpness_fft(roi_img, low_cut=0.30, high_cut=0.70)
    
    # 5. å†…éƒ¨äº®åº¦ç»Ÿè®¡
    valid_brightness = gray[inner_mask > 0]
    feat_bright = np.mean(valid_brightness) if len(valid_brightness) > 0 else 0

    return [
        feat_peak_grad,   # æœ€é‡è¦ï¼šçœ¼ç›/ç¾½æ¯›æœ‰å¤šé”
        feat_mean_grad,   # æ•´ä½“è´¨æ„Ÿ
        feat_std_grad,    # çº¹ç†ä¸°å¯Œåº¦
        feat_fft_mid,     # é¢‘åŸŸä¸­é¢‘
        feat_fft_high,    # é¢‘åŸŸé«˜é¢‘ (å™ªç‚¹æ£€æµ‹)
        feat_bright       # äº®åº¦ (é˜²æ­¢è¿‡æš—è¯¯åˆ¤)
    ]

def main():
    print("=== AI æ¨¡å‹æ·±åº¦ä¼˜åŒ– (éšæœºæ£®æ—ç‰ˆ) ===")
    print("ç±»åˆ«å®šä¹‰: 0-Trash(åºŸç‰‡), 1-Soft(éƒ¨åˆ†å¤±ç„¦), 2-Perfect(å®Œç¾)")
    
    folder = select_folder()
    if not folder: return
    
    csv_file = os.path.join(folder, "labels.csv")
    
    print("æ­£åœ¨åŠ è½½æ•°æ®ä¸æå–å¢å¼ºç‰¹å¾ (Mask-Aware)...")
    data_files = []
    X = []
    y = []
    
    detector = BirdDetector()
    
    # è¯»å– CSV
    raw_data = []
    with open(csv_file, 'r', encoding='utf-8') as f:
        reader = csv.reader(f)
        next(reader, None)
        for row in reader:
            if row and len(row) >= 2:
                try:
                    raw_data.append((row[0], int(row[1])))
                except: continue

    # æå–ç‰¹å¾
    for fname, label in tqdm(raw_data):
        path = os.path.join(folder, fname)
        img = load_best_available_image(path)
        if img is None: continue
        
        roi, _ = detector.detect_and_crop(img, standard_size=ROI_STANDARD_SIZE)
        if roi is None: continue
        
        feats = extract_enhanced_features(roi)
        
        # === æ ¸å¿ƒä¿®æ”¹ï¼šä¸‰çº§åˆ†ç±»æ˜ å°„ ===
        # å‡è®¾ CSV ä¸­ 1=Trash, 2=Soft, 3=Perfect (å…¼å®¹æ—§æ•°æ®çš„ 4 ä¸º Perfect)
        if label == 1:
            cls_label = 0 # Trash
        elif label == 2:
            cls_label = 1 # Soft
        elif label >= 3:
            cls_label = 2 # Perfect
        else:
            continue # è·³è¿‡å¼‚å¸¸æ ‡ç­¾
        
        X.append(feats)
        y.append(cls_label)
        data_files.append(fname)

    X = np.array(X)
    y = np.array(y)
    
    print(f"\næ ·æœ¬å‡†å¤‡å®Œæ¯•: {len(X)} å¼ ")
    print(f"åˆ†å¸ƒ: Trash={np.sum(y==0)}, Soft={np.sum(y==1)}, Perfect={np.sum(y==2)}")
    
    # åˆ’åˆ†æ•°æ®é›†
    X_train, X_test, y_train, y_test, idx_train, idx_test = train_test_split(
        X, y, range(len(data_files)), test_size=0.2, random_state=42
    )

    # === éšæœºæ£®æ—æ·±åº¦è°ƒä¼˜ (Hyperparameter Tuning) ===
    print("\næ­£åœ¨è¿›è¡Œéšæœºæ£®æ—å‚æ•°ç½‘æ ¼æœç´¢ (è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ)...")
    
    # å®šä¹‰åŸºç¡€æ¨¡å‹
    rf = RandomForestClassifier(random_state=42)
    
    # å®šä¹‰å‚æ•°ç½‘æ ¼
    # åŒ…å«æ ‘çš„æ•°é‡ã€æ·±åº¦ã€ä»¥åŠåˆ†è£‚æ ‡å‡†ï¼Œå¯»æ‰¾æœ€ä½³å¹³è¡¡ç‚¹
    param_grid = {
        'n_estimators': [100, 200, 300],        # æ ‘çš„æ•°é‡
        'max_depth': [None, 10, 20, 30],        # æ ‘çš„æ·±åº¦ (é˜²æ­¢è¿‡æ‹Ÿåˆ)
        'min_samples_split': [2, 5, 10],        # èŠ‚ç‚¹åˆ†è£‚æ‰€éœ€æœ€å°æ ·æœ¬æ•°
        'min_samples_leaf': [1, 2, 4],          # å¶å­èŠ‚ç‚¹æœ€å°æ ·æœ¬æ•°
        'max_features': ['sqrt', 'log2']
    }
    
    # å»ºç«‹ç½‘æ ¼æœç´¢ (ä½¿ç”¨ F1-macro ä½œä¸ºè¯„åˆ†æ ‡å‡†ï¼Œå…¼é¡¾åºŸç‰‡å’Œå¥½ç‰‡çš„å¹³è¡¡)
    grid_search = GridSearchCV(
        estimator=rf, 
        param_grid=param_grid, 
        cv=5,           # 5æŠ˜äº¤å‰éªŒè¯
        n_jobs=-1,      # ä½¿ç”¨æ‰€æœ‰CPUæ ¸å¿ƒå¹¶è¡Œè®¡ç®—
        verbose=1,
        scoring='f1_macro'
    )
    
    grid_search.fit(X_train, y_train)
    
    print("-" * 60)
    print(f"æœ€ä½³å‚æ•°: {grid_search.best_params_}")
    print(f"æœ€ä½³è®­ç»ƒé›†éªŒè¯åˆ†æ•°: {grid_search.best_score_:.4f}")
    
    # è·å–æœ€ä½³æ¨¡å‹
    best_clf = grid_search.best_estimator_
    
    # åœ¨ç‹¬ç«‹çš„æµ‹è¯•é›†ä¸ŠéªŒè¯
    y_pred = best_clf.predict(X_test)
    
    # è®¡ç®—æœ€ç»ˆæŒ‡æ ‡
    acc = accuracy_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred, average='macro')
    
    print("-" * 60)
    print(f"ğŸ† æµ‹è¯•é›†è¯„ä¼°ç»“æœ:")
    print(f"   å‡†ç¡®ç‡ (Accuracy): {acc:.4f}")
    print(f"   ç»¼åˆåˆ† (F1 Score): {f1:.4f}")
    
    # æ‰“å°è¯¦ç»†ä¸‰åˆ†ç±»æŠ¥å‘Š
    rpt = classification_report(y_test, y_pred, target_names=CLASS_NAMES, output_dict=True)
    print(f"   [Trash] Recall:   {rpt['Trash']['recall']:.2f} (æŠ“åºŸç‰‡èƒ½åŠ›)")
    print(f"   [Soft]  F1-Score: {rpt['Soft']['f1-score']:.2f}")
    print(f"   [Perfect] Prec:   {rpt['Perfect']['precision']:.2f} (å¥½ç‰‡çº¯åº¦)")
    
    # ä¿å­˜æœ€ä½³æ¨¡å‹ (è¦†ç›–æ—§æ–‡ä»¶)
    joblib.dump(best_clf, "best_bird_model_multiclass.pkl")
    print("\nâœ… ä¼˜åŒ–åçš„æœ€ä½³æ¨¡å‹å·²ä¿å­˜ä¸º best_bird_model_multiclass.pkl")

    # === é”™è¯¯åˆ†æ ===
    print("\næ­£åœ¨ç”Ÿæˆé”™è¯¯åˆ†ææŠ¥å‘Š (Error Analysis)...")
    
    final_pred = best_clf.predict(X_test)
    test_files = [data_files[i] for i in idx_test]
    
    errors = []
    for i in range(len(y_test)):
        if y_test[i] != final_pred[i]:
            true_str = CLASS_NAMES[y_test[i]]
            pred_str = CLASS_NAMES[final_pred[i]]
            
            # åˆ¤æ–­é”™è¯¯ç±»å‹ä¸¥é‡ç¨‹åº¦
            err_type = "ä¸¥é‡" if abs(y_test[i] - final_pred[i]) == 2 else "è½»å¾®"
            
            errors.append({
                'Filename': test_files[i],
                'True_Label': true_str,
                'AI_Predict': pred_str,
                'Severity': err_type
            })
    
    if errors:
        try:
            with open("error_analysis_v2.csv", 'w', newline='', encoding='utf-8-sig') as f:
                writer = csv.DictWriter(f, fieldnames=['Filename', 'True_Label', 'AI_Predict', 'Severity'])
                writer.writeheader()
                writer.writerows(errors)
            print(f"âš ï¸ å‘ç°äº† {len(errors)} ä¸ªè¯¯åˆ¤ã€‚è¯¦æƒ…å·²å†™å…¥ error_analysis_v2.csv")
            print("å»ºè®®é‡ç‚¹æ£€æŸ¥ 'ä¸¥é‡' ç±»å‹çš„è¯¯åˆ¤ (Trash vs Perfect)ã€‚")
        except Exception as e:
            print(f"æ— æ³•ä¿å­˜é”™è¯¯åˆ†ææŠ¥å‘Š: {e}")
    else:
        print("ğŸ‰ å®Œç¾ï¼æµ‹è¯•é›†ä¸Šæ²¡æœ‰è¯¯åˆ¤ã€‚")

    # === çº¿æ€§åˆ†æç»˜å›¾æŠ¥å‘Š ===
    print("\næ­£åœ¨ç”Ÿæˆçº¿æ€§åˆ†æç»˜å›¾æŠ¥å‘Š...")
    
    # 1. è®¡ç®—æ¨¡å‹é¢„æµ‹è¯„åˆ† (Weighted Score)
    # å°†æ¦‚ç‡è½¬æ¢ä¸ºè¿ç»­åˆ†æ•°: 0*P(Trash) + 1*P(Soft) + 2*P(Perfect)
    y_probs = best_clf.predict_proba(X_test)
    model_scores = y_probs[:, 0] * 0 + y_probs[:, 1] * 1 + y_probs[:, 2] * 2
    
    # 2. çº¿æ€§å›å½’
    slope, intercept, r_value, p_value, std_err = stats.linregress(y_test, model_scores)
    r_squared = r_value ** 2
    
    print("\n" + "=" * 60)
    print(f"ğŸ“Š æ¨¡å‹è¯„åˆ†çº¿æ€§å›å½’æŠ¥å‘Š (Test Set)")
    print("-" * 60)
    print(f"ç›¸å…³ç³»æ•° (r)      : {r_value:.4f}")
    print(f"å†³å®šç³»æ•° (RÂ²)     : {r_squared:.4f}")
    print(f"På€¼ (P-value)     : {p_value:.4e}")
    print("-" * 60)
    print(f"ğŸ“ˆ å›å½’æ–¹ç¨‹: Predicted_Score = {slope:.2f} * True_Label + {intercept:.2f}")
    print("=" * 60)
    
    # 3. ç»˜å›¾
    plt.figure(figsize=(10, 6))
    
    # æ·»åŠ æŠ–åŠ¨ (Jitter)
    jitter = np.random.normal(0, 0.05, size=len(y_test))
    plt.scatter(y_test + jitter, model_scores, alpha=0.6, c='blue', edgecolors='w', label='Test Samples')
    
    # ç»˜åˆ¶å›å½’çº¿
    x_fit = np.linspace(min(y_test), max(y_test), 100)
    y_fit = slope * x_fit + intercept
    plt.plot(x_fit, y_fit, 'r--', linewidth=2, label=f'Fit: $R^2$={r_squared:.2f}')
    
    # ç†æƒ³çº¿
    plt.plot([0, 2], [0, 2], 'g:', alpha=0.5, label='Ideal (y=x)')
    
    plt.title(f'Linear Regression: Model Score vs True Label')
    plt.xlabel('True Label (0:Trash, 1:Soft, 2:Perfect)')
    plt.ylabel('Model Weighted Score (0.0 - 2.0)')
    plt.xticks([0, 1, 2], ['Trash', 'Soft', 'Perfect'])
    plt.yticks(np.arange(0, 2.5, 0.5))
    plt.grid(True, linestyle='--', alpha=0.5)
    plt.legend()
    plt.tight_layout()
    plt.show()

if __name__ == "__main__":
    import cv2 
    main()